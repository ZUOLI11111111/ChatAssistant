[llm] #DeepSeek:
model = "deepseek-chat"                         # The LLM model to use
base_url = "https://api.deepseek.com/v1"        # API endpoint URL
api_key = "sk-" # Your API key
max_tokens = 8192                               # Maximum number of tokens in the response
temperature = 0.0